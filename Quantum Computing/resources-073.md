### ü§ñ GPU Performance - RDNA4 vs. RDNA3 and Blackwell vs. Ada Lovelace

This article compares the Instruction Per Clock (IPC) performance of AMD's RDNA 4 and RDNA 3 architectures, and Nvidia's Blackwell and Ada Lovelace architectures, based on a ComputerBase analysis.  The focus is on rasterizer and raytracing performance differences.

Key Points:

‚Ä¢ RDNA 4 shows noticeable improvements in rasterization and, especially, raytracing performance.


‚Ä¢ Blackwell architecture shows limited performance gains compared to Ada Lovelace.


‚Ä¢ The ComputerBase analysis provides a detailed comparison of these GPU architectures.


üîó Resources:

‚Ä¢ [ComputerBase Article](https://computerbase.de/artikel/grafikkarten/blackwell-lovelace-rdna-4-rdna-3-performance-vergleich.93228) -  Detailed GPU performance comparison

![Image](https://pbs.twimg.com/media/GuHpFiJWcAA0zTd?format=png&name=small)
![Image](https://pbs.twimg.com/media/GuHpFk7WcAACjHN?format=png&name=small)
![Image](https://pbs.twimg.com/media/GuHpFk1WAAE4b8P?format=png&name=small)
![Image](https://pbs.twimg.com/media/GuHpFk1XsAAb4eL?format=png&name=small)


---

### ü§ñ Robotics - RSS Conference and Recruitment

This article announces the author's attendance at the RSS conference and details their recruitment needs for a founding scientist and new models/tools for their robot.

Key Points:

‚Ä¢  Seeking a founding scientist to join their core team.


‚Ä¢  Looking for new models and tools to enhance their robot for customers.


‚Ä¢  Open to discussing robotic insights at the RSS conference.



---

### ü§ñ Reward Function Design - Avoiding Reward Hacking in Chemistry

This article discusses a 3.5k-word essay on designing reward functions for chemistry applications while mitigating reward hacking.  The essay details methods used to prevent reward hacking during the training of a scientific reasoning model called ether0.

Key Points:

‚Ä¢  Provides comprehensive strategies for designing reward functions in chemistry.


‚Ä¢  Explores various reward hacking avoidance techniques.


‚Ä¢  Details experiences in training the ether0 scientific reasoning model.


üîó Resources:

![Image](https://pbs.twimg.com/media/GuDrHN3WEAAc5T0?format=jpg&name=small)


---

### üí° Personal Reflection - Mountain Trip and Mental Well-being

This article describes a personal experience of a weekend trip to the mountains, emphasizing the restorative effect of nature on mental well-being.

Key Points:

‚Ä¢  Highlights the positive impact of nature on mental well-being.


‚Ä¢  Shares a personal experience of a mountain trip.



üîó Resources:

![Image](https://pbs.twimg.com/media/GuCxw3oWUAAyn8l?format=jpg&name=small)


---

### ü§ñ Reinforcement Learning - Asynchronous RL for Improved GPU Utilization

This article contrasts synchronous and asynchronous reinforcement learning (RL), highlighting the advantages of asynchronous RL for maximizing GPU utilization.  It focuses on AReaL-boba¬≤'s asynchronous approach.

Key Points:

‚Ä¢ Synchronous RL wastes GPU resources due to batch waiting times.


‚Ä¢ Asynchronous RL in AReaL-boba¬≤ improves GPU utilization by decoupling generation and training.


‚Ä¢ Asynchronous RL represents a significant advancement in reinforcement learning.


üîó Resources:

![Image](https://pbs.twimg.com/media/Gsm5k-YasAIbvXj?format=jpg&name=small)


---

### ü§ñ NLP - Personalizing AI Assistants using User Feedback (SynthesizeMe)

This article introduces SynthesizeMe, a new approach for personalizing AI assistants by leveraging user feedback.  The method uses both implicit and explicit feedback to tailor the AI assistant to individual users.

Key Points:

‚Ä¢  SynthesizeMe personalizes AI assistants based on user feedback.


‚Ä¢  It utilizes both implicit and explicit feedback mechanisms.


‚Ä¢  The approach aims to create more personalized and effective AI interactions.


üîó Resources:

![Image](https://pbs.twimg.com/amplify_video_thumb/1932468358584373248/img/3U2d6qLa9MPTGexd.jpg)


---

### ü§ñ Large Language Model Fine-tuning - Arithmo-Mistral-7B Results

This article suggests adding the results of Arithmo-Mistral-7B (4-bit QLoRA on 1x4090) to a research paper. It highlights the model's achievement as the first to demonstrate improved results from fine-tuning on the Mistral-7B model.

Key Points:

‚Ä¢  Arithmo-Mistral-7B shows improved results from fine-tuning on Mistral-7B.


‚Ä¢  The model uses 4-bit QLoRA on a single 4090 GPU.


‚Ä¢  The results are available in the linked Github repository.


üîó Resources:

‚Ä¢ [Arithmo-Mistral-7B Details](https://x.com/akjindal53244/status/1715221428319220129?s=20) -  More details on the model
‚Ä¢ [Arithmo-Mistral-7B Github](https://github.com/akjindal53244/Arithmo-Mistral-7B) -  Github repository

![Image](https://pbs.twimg.com/media/F82wSaeb0AAcxgM?format=jpg&name=900x900)
![Image](https://pbs.twimg.com/media/F82wSaWbEAA2viK?format=jpg&name=small)


---

### ü§ñ Reward Model Training - Comparison with Prior Work

This article discusses the conceptual differences between a specific reward model training approach and the work presented in  https://arxiv.org/abs/2110.14168. The key difference lies in training a per-"reasoning step" model versus a per-token reward model.


Key Points:

‚Ä¢  Compares a new reward model training approach with prior work.


‚Ä¢  Highlights the key difference in training a per-reasoning step model.


‚Ä¢  The discussion focuses on the conceptual distinctions between the two methods.


üîó Resources:

‚Ä¢ [Related Work](https://arxiv.org/abs/2110.14168) -  Prior work on reward model training


---

### ü§ñ Robotics - RSS2025 Conference Attendance and Talk Announcement

This article announces the author's attendance at the RSS2025 conference in Los Angeles and their planned presentation on Gemini Robotics.  The author also mentions participation in the SemRob and RoboEval workshops.

Key Points:

‚Ä¢  Announcement of attendance at RSS2025 in Los Angeles.


‚Ä¢  Presentation on Gemini Robotics planned.


‚Ä¢  Participation in SemRob and RoboEval workshops.


---

### ü§ñ Geometric Deep Learning - Book Chapter Release

This article announces the release of the first draft of chapter 'g' of a book on geometric deep learning. The chapter covers graphs, graph neural networks (GNNs), and large language models (LLMs).

Key Points:

‚Ä¢  First draft of chapter 'g' on geometric deep learning released.


‚Ä¢  Covers graphs, GNNs, and LLMs.



üîó Resources:

![Image](https://pbs.twimg.com/media/Gt5iT7PWUAEMIkc?format=jpg&name=small)


---

### ‚≠êÔ∏è Support

If you liked reading this report, please star ‚≠êÔ∏è this repository and follow me on [Github](https://github.com/Drix10), [ùïè (previously known as Twitter)](https://x.com/DRIX_10_) to help others discover these resources and regular updates.

---